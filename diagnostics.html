<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Speech Recognition Test & Diagnostics</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            margin-bottom: 20px;
        }
        h1, h2 {
            color: #333;
        }
        .diagnostic {
            background: #f9f9f9;
            border: 1px solid #ddd;
            padding: 15px;
            margin: 10px 0;
            border-radius: 5px;
        }
        .error {
            background: #fee;
            border-color: #fcc;
            color: #c00;
        }
        .success {
            background: #efe;
            border-color: #cfc;
            color: #060;
        }
        .warning {
            background: #ffe;
            border-color: #ffc;
            color: #660;
        }
        button {
            background: #007bff;
            color: white;
            border: none;
            padding: 10px 20px;
            margin: 5px;
            border-radius: 5px;
            cursor: pointer;
            font-size: 16px;
        }
        button:hover {
            background: #0056b3;
        }
        button:disabled {
            background: #ccc;
            cursor: not-allowed;
        }
        .stop-button {
            background: #dc3545;
        }
        .stop-button:hover {
            background: #c82333;
        }
        #transcript, #altTranscript {
            background: #f9f9f9;
            border: 1px solid #ddd;
            padding: 15px;
            margin: 10px 0;
            min-height: 100px;
            border-radius: 5px;
        }
        .log-entry {
            padding: 5px;
            margin: 2px 0;
            font-family: monospace;
            font-size: 14px;
        }
        #debugLog {
            background: #f0f0f0;
            border: 1px solid #ccc;
            padding: 10px;
            max-height: 300px;
            overflow-y: auto;
            font-family: monospace;
            font-size: 12px;
        }
        .tabs {
            display: flex;
            border-bottom: 2px solid #ddd;
            margin-bottom: 20px;
        }
        .tab {
            padding: 10px 20px;
            cursor: pointer;
            background: #f9f9f9;
            border: 1px solid #ddd;
            border-bottom: none;
            margin-right: 5px;
        }
        .tab.active {
            background: white;
            border-top: 3px solid #007bff;
        }
        .tab-content {
            display: none;
        }
        .tab-content.active {
            display: block;
        }
        .network-test {
            display: inline-block;
            margin: 10px 0;
        }
        .mic-indicator {
            display: inline-block;
            width: 20px;
            height: 20px;
            border-radius: 50%;
            background: #ccc;
            margin-left: 10px;
            vertical-align: middle;
        }
        .mic-indicator.active {
            background: #f00;
            animation: pulse 1s infinite;
        }
        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.5; }
            100% { opacity: 1; }
        }
    </style>
</head>
<body>
    <h1>Speech Recognition Diagnostics & Alternative Solutions</h1>

    <div class="tabs">
        <div class="tab active" onclick="switchTab('diagnostics')">Diagnostics</div>
        <div class="tab" onclick="switchTab('chrome')">Chrome Speech API Test</div>
        <div class="tab" onclick="switchTab('alternative')">Alternative Solution</div>
    </div>

    <!-- Diagnostics Tab -->
    <div id="diagnostics" class="tab-content active">
        <div class="container">
            <h2>System Diagnostics</h2>
            
            <div class="diagnostic" id="browserCheck">
                <strong>Browser Detection:</strong> <span id="browserInfo">Checking...</span>
            </div>
            
            <div class="diagnostic" id="apiCheck">
                <strong>Web Speech API Support:</strong> <span id="apiInfo">Checking...</span>
            </div>
            
            <div class="diagnostic" id="micCheck">
                <strong>Microphone Permission:</strong> <span id="micInfo">Not checked yet</span>
                <button onclick="checkMicrophone()">Test Microphone</button>
            </div>
            
            <div class="diagnostic" id="networkCheck">
                <strong>Network Connectivity:</strong> <span id="networkInfo">Checking...</span>
                <div class="network-test">
                    <button onclick="testGoogleAPI()">Test Google API</button>
                    <button onclick="testCORS()">Test CORS</button>
                </div>
            </div>
            
            <div class="diagnostic" id="httpsCheck">
                <strong>HTTPS Status:</strong> <span id="httpsInfo">Checking...</span>
            </div>
            
            <h3>Common Chrome Speech API Issues</h3>
            <div class="diagnostic warning">
                <h4>1. Time Limit (60-120 seconds)</h4>
                <p>Chrome's Speech API automatically stops after 60-120 seconds and throws a network error. Solution: Implement auto-restart on error.</p>
            </div>
            
            <div class="diagnostic warning">
                <h4>2. Non-Browser Environments</h4>
                <p>The API may fail in Electron apps or other non-standard browser environments. Google promotes their Cloud Speech API for these cases.</p>
            </div>
            
            <div class="diagnostic warning">
                <h4>3. API Key Requirements</h4>
                <p>Some Chromium builds require a Google Speech API key. Check your browser's documentation.</p>
            </div>
            
            <div class="diagnostic warning">
                <h4>4. Network Errors Despite Good Connection</h4>
                <p>The API may report network errors even with good connectivity due to internal limitations or quota issues.</p>
            </div>
        </div>
    </div>

    <!-- Chrome Speech API Tab -->
    <div id="chrome" class="tab-content">
        <div class="container">
            <h2>Chrome Speech API Test</h2>
            
            <div>
                <button id="startBtn" onclick="startRecognition()">Start Recognition</button>
                <button id="stopBtn" class="stop-button" onclick="stopRecognition()" disabled>Stop Recognition</button>
                <span class="mic-indicator" id="micIndicator"></span>
            </div>
            
            <h3>Settings</h3>
            <div>
                <label>
                    <input type="checkbox" id="continuous" checked> Continuous Recognition
                </label>
                <br>
                <label>
                    <input type="checkbox" id="interim" checked> Show Interim Results
                </label>
                <br>
                <label>
                    <input type="checkbox" id="autoRestart" checked> Auto-restart on Error (for 60s limit)
                </label>
            </div>
            
            <h3>Transcript</h3>
            <div id="transcript"></div>
            
            <h3>Debug Log</h3>
            <div id="debugLog"></div>
        </div>
    </div>

    <!-- Alternative Solution Tab -->
    <div id="alternative" class="tab-content">
        <div class="container">
            <h2>Alternative: MediaRecorder API with External Service</h2>
            <p>This approach uses the MediaRecorder API to capture audio and can send it to various speech recognition services.</p>
            
            <div>
                <button id="altStartBtn" onclick="startAltRecording()">Start Recording</button>
                <button id="altStopBtn" class="stop-button" onclick="stopAltRecording()" disabled>Stop Recording</button>
                <span class="mic-indicator" id="altMicIndicator"></span>
            </div>
            
            <h3>Recording Status</h3>
            <div id="recordingStatus">Ready to record</div>
            
            <h3>Audio Recordings</h3>
            <div id="audioList"></div>
            
            <h3>Transcript (Simulated)</h3>
            <div id="altTranscript">
                <em>Note: This demo simulates transcription. In production, you would send the audio to a service like:</em>
                <ul>
                    <li>OpenAI Whisper API</li>
                    <li>Google Cloud Speech-to-Text</li>
                    <li>Azure Speech Services</li>
                    <li>AWS Transcribe</li>
                    <li>Local Whisper.js (for offline use)</li>
                </ul>
            </div>
            
            <h3>Implementation Notes</h3>
            <div class="diagnostic">
                <h4>Advantages of this approach:</h4>
                <ul>
                    <li>No 60-second time limit</li>
                    <li>Works in all environments (Electron, PWA, etc.)</li>
                    <li>Can use any speech recognition backend</li>
                    <li>Can work offline with local models</li>
                    <li>Full control over audio quality and processing</li>
                </ul>
            </div>
        </div>
    </div>

    <script>
        // Tab switching
        function switchTab(tabName) {
            document.querySelectorAll('.tab').forEach(tab => tab.classList.remove('active'));
            document.querySelectorAll('.tab-content').forEach(content => content.classList.remove('active'));
            
            event.target.classList.add('active');
            document.getElementById(tabName).classList.add('active');
        }

        // Logging function
        function log(message, type = 'info') {
            const logDiv = document.getElementById('debugLog');
            const entry = document.createElement('div');
            entry.className = `log-entry ${type}`;
            entry.textContent = `[${new Date().toLocaleTimeString()}] ${message}`;
            logDiv.appendChild(entry);
            logDiv.scrollTop = logDiv.scrollHeight;
        }

        // Diagnostics
        function runDiagnostics() {
            // Browser detection
            const browserInfo = document.getElementById('browserInfo');
            const userAgent = navigator.userAgent;
            let browser = 'Unknown';
            
            if (userAgent.includes('Chrome')) browser = 'Chrome';
            else if (userAgent.includes('Firefox')) browser = 'Firefox';
            else if (userAgent.includes('Safari')) browser = 'Safari';
            else if (userAgent.includes('Edge')) browser = 'Edge';
            
            browserInfo.textContent = `${browser} - ${userAgent}`;
            
            // API Support
            const apiInfo = document.getElementById('apiInfo');
            const apiCheck = document.getElementById('apiCheck');
            
            if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
                apiInfo.textContent = 'Supported';
                apiCheck.className = 'diagnostic success';
            } else {
                apiInfo.textContent = 'Not supported';
                apiCheck.className = 'diagnostic error';
            }
            
            // HTTPS Check
            const httpsInfo = document.getElementById('httpsInfo');
            const httpsCheck = document.getElementById('httpsCheck');
            
            if (location.protocol === 'https:' || location.hostname === 'localhost') {
                httpsInfo.textContent = 'Secure context (HTTPS or localhost)';
                httpsCheck.className = 'diagnostic success';
            } else {
                httpsInfo.textContent = 'Not secure - Speech API requires HTTPS';
                httpsCheck.className = 'diagnostic error';
            }
            
            // Network check
            checkNetworkStatus();
        }

        // Network status check
        function checkNetworkStatus() {
            const networkInfo = document.getElementById('networkInfo');
            const networkCheck = document.getElementById('networkCheck');
            
            if (navigator.onLine) {
                networkInfo.textContent = 'Online';
                networkCheck.className = 'diagnostic success';
            } else {
                networkInfo.textContent = 'Offline';
                networkCheck.className = 'diagnostic error';
            }
        }

        // Microphone check
        async function checkMicrophone() {
            const micInfo = document.getElementById('micInfo');
            const micCheck = document.getElementById('micCheck');
            
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                micInfo.textContent = 'Permission granted';
                micCheck.className = 'diagnostic success';
                stream.getTracks().forEach(track => track.stop());
            } catch (error) {
                micInfo.textContent = `Permission denied: ${error.message}`;
                micCheck.className = 'diagnostic error';
            }
        }

        // Test Google API connectivity
        async function testGoogleAPI() {
            const networkInfo = document.getElementById('networkInfo');
            try {
                // Try to reach Google's servers
                const response = await fetch('https://www.google.com/favicon.ico', { mode: 'no-cors' });
                networkInfo.textContent = 'Online - Google reachable';
            } catch (error) {
                networkInfo.textContent = `Online - Google unreachable: ${error.message}`;
            }
        }

        // Test CORS
        async function testCORS() {
            const networkInfo = document.getElementById('networkInfo');
            try {
                // This will fail due to CORS, but that's expected
                const response = await fetch('https://speech.googleapis.com/v1/speech:recognize');
                networkInfo.textContent = 'CORS test completed';
            } catch (error) {
                networkInfo.textContent = `CORS test: ${error.message} (this is normal)`;
            }
        }

        // Chrome Speech Recognition
        let recognition;
        let isRecognizing = false;
        let autoRestartEnabled = true;
        let restartTimer;

        function initRecognition() {
            const SpeechRecognition = window.webkitSpeechRecognition || window.SpeechRecognition;
            
            if (!SpeechRecognition) {
                log('Speech Recognition not supported', 'error');
                return;
            }
            
            recognition = new SpeechRecognition();
            recognition.continuous = document.getElementById('continuous').checked;
            recognition.interimResults = document.getElementById('interim').checked;
            recognition.lang = 'en-US';
            
            recognition.onstart = () => {
                log('Recognition started');
                isRecognizing = true;
                document.getElementById('startBtn').disabled = true;
                document.getElementById('stopBtn').disabled = false;
                document.getElementById('micIndicator').classList.add('active');
            };
            
            recognition.onend = () => {
                log('Recognition ended');
                isRecognizing = false;
                document.getElementById('startBtn').disabled = false;
                document.getElementById('stopBtn').disabled = true;
                document.getElementById('micIndicator').classList.remove('active');
                
                // Auto-restart if enabled and it was an unexpected end
                if (autoRestartEnabled && document.getElementById('autoRestart').checked) {
                    log('Auto-restarting in 1 second...', 'warning');
                    restartTimer = setTimeout(() => {
                        if (!isRecognizing) {
                            startRecognition();
                        }
                    }, 1000);
                }
            };
            
            recognition.onerror = (event) => {
                log(`Error: ${event.error} - ${event.message || 'No message'}`, 'error');
                
                if (event.error === 'network') {
                    log('Network error detected - this often happens after 60-120 seconds', 'warning');
                    document.getElementById('transcript').innerHTML += 
                        '<div class="error">Network error - Chrome Speech API has timed out (60-120s limit)</div>';
                }
            };
            
            recognition.onresult = (event) => {
                let finalTranscript = '';
                let interimTranscript = '';
                
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript;
                    if (event.results[i].isFinal) {
                        finalTranscript += transcript + ' ';
                        log(`Final: "${transcript}" (confidence: ${event.results[i][0].confidence})`);
                    } else {
                        interimTranscript += transcript;
                        log(`Interim: "${transcript}"`);
                    }
                }
                
                const transcriptDiv = document.getElementById('transcript');
                if (finalTranscript) {
                    transcriptDiv.innerHTML += `<strong>${finalTranscript}</strong><br>`;
                }
                if (interimTranscript && document.getElementById('interim').checked) {
                    transcriptDiv.innerHTML += `<em>${interimTranscript}</em><br>`;
                }
                
                transcriptDiv.scrollTop = transcriptDiv.scrollHeight;
            };
        }

        function startRecognition() {
            autoRestartEnabled = true;
            clearTimeout(restartTimer);
            
            if (!recognition) {
                initRecognition();
            }
            
            if (recognition) {
                recognition.continuous = document.getElementById('continuous').checked;
                recognition.interimResults = document.getElementById('interim').checked;
                
                try {
                    recognition.start();
                    log('Starting recognition...');
                } catch (error) {
                    log(`Failed to start: ${error.message}`, 'error');
                }
            }
        }

        function stopRecognition() {
            autoRestartEnabled = false;
            clearTimeout(restartTimer);
            
            if (recognition && isRecognizing) {
                recognition.stop();
                log('Stopping recognition...');
            }
        }

        // Alternative recording solution
        let mediaRecorder;
        let audioChunks = [];
        let recordingStartTime;

        async function startAltRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];
                
                mediaRecorder.ondataavailable = (event) => {
                    audioChunks.push(event.data);
                };
                
                mediaRecorder.onstop = () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    const audioUrl = URL.createObjectURL(audioBlob);
                    const duration = (Date.now() - recordingStartTime) / 1000;
                    
                    // Create audio element
                    const audioList = document.getElementById('audioList');
                    const audioElement = document.createElement('div');
                    audioElement.innerHTML = `
                        <audio controls src="${audioUrl}"></audio>
                        <span>Duration: ${duration.toFixed(1)}s</span>
                        <button onclick="simulateTranscription('${duration.toFixed(1)}')">Simulate Transcription</button>
                        <hr>
                    `;
                    audioList.appendChild(audioElement);
                    
                    // Stop all tracks
                    stream.getTracks().forEach(track => track.stop());
                    
                    document.getElementById('recordingStatus').textContent = 'Recording saved';
                };
                
                mediaRecorder.start();
                recordingStartTime = Date.now();
                
                document.getElementById('altStartBtn').disabled = true;
                document.getElementById('altStopBtn').disabled = false;
                document.getElementById('altMicIndicator').classList.add('active');
                document.getElementById('recordingStatus').textContent = 'Recording...';
                
                // Update duration every second
                const durationInterval = setInterval(() => {
                    if (mediaRecorder.state === 'recording') {
                        const duration = (Date.now() - recordingStartTime) / 1000;
                        document.getElementById('recordingStatus').textContent = 
                            `Recording... ${duration.toFixed(1)}s`;
                    } else {
                        clearInterval(durationInterval);
                    }
                }, 100);
                
            } catch (error) {
                console.error('Error starting recording:', error);
                document.getElementById('recordingStatus').textContent = 
                    `Error: ${error.message}`;
            }
        }

        function stopAltRecording() {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
                document.getElementById('altStartBtn').disabled = false;
                document.getElementById('altStopBtn').disabled = true;
                document.getElementById('altMicIndicator').classList.remove('active');
            }
        }

        function simulateTranscription(duration) {
            const transcript = document.getElementById('altTranscript');
            transcript.innerHTML = `
                <div class="success">
                    <strong>Simulated Transcription Result:</strong><br>
                    "This is a simulated transcription of ${duration} seconds of audio. 
                    In a real implementation, this audio would be sent to a speech recognition service 
                    like Whisper API, Google Cloud Speech-to-Text, or processed locally with Whisper.js."
                </div>
                <br>
                <div class="diagnostic">
                    <strong>Implementation Example:</strong><br>
                    <code>
                    // Send to Whisper API<br>
                    const formData = new FormData();<br>
                    formData.append('file', audioBlob, 'recording.webm');<br>
                    formData.append('model', 'whisper-1');<br>
                    <br>
                    const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {<br>
                    &nbsp;&nbsp;method: 'POST',<br>
                    &nbsp;&nbsp;headers: { 'Authorization': 'Bearer YOUR_API_KEY' },<br>
                    &nbsp;&nbsp;body: formData<br>
                    });<br>
                    const result = await response.json();<br>
                    console.log(result.text);
                    </code>
                </div>
            `;
        }

        // Initialize on load
        window.addEventListener('load', () => {
            runDiagnostics();
            
            // Monitor online/offline status
            window.addEventListener('online', checkNetworkStatus);
            window.addEventListener('offline', checkNetworkStatus);
        });
    </script>
</body>
</html>